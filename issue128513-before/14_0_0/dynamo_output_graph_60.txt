class GraphModule(torch.nn.Module):
    def forward(self, L_stack0_0_: "i32[13, 3][3, 1]cpu", L_stack0_1_: "i32[13, 3][3, 1]cpu", L_stack0_2_: "i32[13, 3][3, 1]cpu", L_stack0_3_: "i32[13, 3][3, 1]cpu", L_stack0_4_: "i32[13, 3][3, 1]cpu", L_stack0_5_: "i32[13, 3][3, 1]cpu", L_stack0_6_: "i32[13, 3][3, 1]cpu", L_stack0_7_: "i32[13, 3][3, 1]cpu", L_stack0_8_: "i32[13, 3][3, 1]cpu", L_stack0_9_: "i32[13, 3][3, 1]cpu", L_stack0_10_: "i32[13, 3][3, 1]cpu", L_stack0_11_: "i32[13, 3][3, 1]cpu"):
        l_stack0_0_ = L_stack0_0_
        l_stack0_1_ = L_stack0_1_
        l_stack0_2_ = L_stack0_2_
        l_stack0_3_ = L_stack0_3_
        l_stack0_4_ = L_stack0_4_
        l_stack0_5_ = L_stack0_5_
        l_stack0_6_ = L_stack0_6_
        l_stack0_7_ = L_stack0_7_
        l_stack0_8_ = L_stack0_8_
        l_stack0_9_ = L_stack0_9_
        l_stack0_10_ = L_stack0_10_
        l_stack0_11_ = L_stack0_11_
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1172 in torch_dynamo_resume_in__bigbird_block_rand_mask_with_head_at_1165, code: rand_attn[nh] = rand_attn[nh][global_block_top : num_blocks - global_block_bottom, :]
        wrapped_getitem: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem(l_stack0_0_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_0_ = None
        wrapped_getitem_1: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_1(l_stack0_1_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_1_ = None
        wrapped_getitem_2: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_2(l_stack0_2_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_2_ = None
        wrapped_getitem_3: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_3(l_stack0_3_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_3_ = None
        wrapped_getitem_4: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_4(l_stack0_4_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_4_ = None
        wrapped_getitem_5: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_5(l_stack0_5_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_5_ = None
        wrapped_getitem_6: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_6(l_stack0_6_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_6_ = None
        wrapped_getitem_7: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_7(l_stack0_7_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_7_ = None
        wrapped_getitem_8: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_8(l_stack0_8_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_8_ = None
        wrapped_getitem_9: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_9(l_stack0_9_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_9_ = None
        wrapped_getitem_10: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_10(l_stack0_10_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_10_ = None
        wrapped_getitem_11: "i32[11, 3][3, 1]cpu" = torch__dynamo_utils_wrapped_getitem_11(l_stack0_11_, (slice(1, 12, None), slice(None, None, None)));  l_stack0_11_ = None
        return (wrapped_getitem, wrapped_getitem_1, wrapped_getitem_2, wrapped_getitem_3, wrapped_getitem_4, wrapped_getitem_5, wrapped_getitem_6, wrapped_getitem_7, wrapped_getitem_8, wrapped_getitem_9, wrapped_getitem_10, wrapped_getitem_11)
        