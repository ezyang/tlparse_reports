<pre style="background-color:#ffffff;">
<span style="color:#323232;">
</span><span style="font-style:italic;color:#969896;"># AOT ID: [&#39;69_inference&#39;]
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">ctypes </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">c_void_p, c_long
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">torch
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">math
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">random
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">os
</span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">tempfile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">math </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">inf, nan
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.hooks </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">run_intermediate_hooks
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">maybe_profile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.memory_planning </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">_align </span><span style="font-weight:bold;color:#a71d5d;">as </span><span style="color:#323232;">align
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">device, empty_strided
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.async_compile </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">AsyncCompile
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.select_algorithm </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">extern_kernels
</span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.codegen.multi_kernel </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">MultiKernelCall
</span><span style="color:#323232;">
</span><span style="color:#323232;">aten </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.aten
</span><span style="color:#323232;">inductor_ops </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor
</span><span style="color:#323232;">_quantized </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops._quantized
</span><span style="color:#323232;">assert_size_stride </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards.assert_size_stride
</span><span style="color:#323232;">empty_strided_cpu </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cpu
</span><span style="color:#323232;">empty_strided_cuda </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.</span><span style="color:#0086b3;">_C</span><span style="color:#323232;">._dynamo.guards._empty_strided_cuda
</span><span style="color:#323232;">alloc_from_pool </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._alloc_from_pool
</span><span style="color:#323232;">reinterpret_tensor </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">torch.ops.inductor._reinterpret_tensor
</span><span style="color:#323232;">async_compile </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">AsyncCompile()
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__softmax_add_mul_rsub_0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr3)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = -std::numeric_limits&lt;float&gt;::infinity();
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(-std::numeric_limits&lt;float&gt;::infinity());
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                        auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                        auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                        auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                        auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                        tmp_acc0_vec = at::vec::maximum(tmp_acc0_vec, tmp13);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = max_propagate_nan(tmp_acc0, at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return at::vec::maximum(x, y); }, tmp_acc0_vec));
</span><span style="color:#183691;">                    out_ptr0[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = 0;
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(0);
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp14 = out_ptr0[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                        auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                        auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                        auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                        auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                        auto tmp15 = at::vec::Vectorized&lt;float&gt;(tmp14);
</span><span style="color:#183691;">                        auto tmp16 = tmp13 - tmp15;
</span><span style="color:#183691;">                        auto tmp17 = tmp16.exp();
</span><span style="color:#183691;">                        tmp17.store(out_ptr1 + static_cast&lt;long&gt;(x1 + (832L*x0)));
</span><span style="color:#183691;">                        tmp_acc0_vec = tmp_acc0_vec + tmp17;
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return x + y; }, tmp_acc0_vec);
</span><span style="color:#183691;">                    out_ptr2[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = out_ptr2[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">                    auto tmp4 = at::vec::convert&lt;bfloat16&gt;(tmp3);
</span><span style="color:#183691;">                    tmp4.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__to_copy_cat_stack_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int32_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const int32_t* in_ptr0,
</span><span style="color:#183691;">                       const int32_t* in_ptr1,
</span><span style="color:#183691;">                       const int32_t* in_ptr2,
</span><span style="color:#183691;">                       const int32_t* in_ptr3,
</span><span style="color:#183691;">                       const int32_t* in_ptr4,
</span><span style="color:#183691;">                       const int32_t* in_ptr5,
</span><span style="color:#183691;">                       const int32_t* in_ptr6,
</span><span style="color:#183691;">                       const int32_t* in_ptr7,
</span><span style="color:#183691;">                       const int32_t* in_ptr8,
</span><span style="color:#183691;">                       const int32_t* in_ptr9,
</span><span style="color:#183691;">                       const int32_t* in_ptr10,
</span><span style="color:#183691;">                       const int32_t* in_ptr11,
</span><span style="color:#183691;">                       const int32_t* in_ptr12,
</span><span style="color:#183691;">                       const bfloat16* in_ptr13,
</span><span style="color:#183691;">                       int32_t* out_ptr0,
</span><span style="color:#183691;">                       int32_t* out_ptr1,
</span><span style="color:#183691;">                       int32_t* out_ptr2,
</span><span style="color:#183691;">                       int32_t* out_ptr3,
</span><span style="color:#183691;">                       int32_t* out_ptr4,
</span><span style="color:#183691;">                       int32_t* out_ptr5,
</span><span style="color:#183691;">                       int32_t* out_ptr6,
</span><span style="color:#183691;">                       int32_t* out_ptr7,
</span><span style="color:#183691;">                       int32_t* out_ptr8,
</span><span style="color:#183691;">                       int32_t* out_ptr9,
</span><span style="color:#183691;">                       int32_t* out_ptr10,
</span><span style="color:#183691;">                       int32_t* out_ptr11,
</span><span style="color:#183691;">                       int64_t* out_ptr12,
</span><span style="color:#183691;">                       bfloat16* out_ptr13,
</span><span style="color:#183691;">                       bfloat16* out_ptr14,
</span><span style="color:#183691;">                       bfloat16* out_ptr15,
</span><span style="color:#183691;">                       bfloat16* out_ptr16,
</span><span style="color:#183691;">                       bfloat16* out_ptr17,
</span><span style="color:#183691;">                       bfloat16* out_ptr18,
</span><span style="color:#183691;">                       bfloat16* out_ptr19,
</span><span style="color:#183691;">                       bfloat16* out_ptr20)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr0[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr0[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr1[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr1[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr2 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr2 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr2[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr2[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr3 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr3[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr3[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr4 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr4[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr4[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr5 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr5 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr5[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr5[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr6 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr6[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr6[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr7 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr7 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr7[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr7[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr8 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr8 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr8[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr8[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr9 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr9 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr9[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr9[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr10 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr10 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr10[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr10[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(32L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr11 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr11 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(32L); x0&lt;static_cast&lt;long&gt;(33L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr11[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            out_ptr11[static_cast&lt;long&gt;(x0)] = tmp0;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(384L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;int32_t&gt;::loadu(in_ptr12 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            auto tmp1 = at::vec::convert&lt;int64_t,2,int32_t,1&gt;(tmp0);
</span><span style="color:#183691;">            tmp1.store(out_ptr12 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp simd simdlen(8) 
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(384L); x0&lt;static_cast&lt;long&gt;(396L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = in_ptr12[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">            auto tmp1 = c10::convert&lt;int64_t&gt;(tmp0);
</span><span style="color:#183691;">            out_ptr12[static_cast&lt;long&gt;(x0)] = tmp1;
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr13 + static_cast&lt;long&gt;(x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr13 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr14 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr13 + static_cast&lt;long&gt;(49152L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr15 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr13 + static_cast&lt;long&gt;(98304L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr16 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr13 + static_cast&lt;long&gt;(589824L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr17 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr18 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(192L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = out_ptr12[static_cast&lt;long&gt;((33L*x0) + (33L*(c10::div_floor_integer((x2 + (64L*x1)), 135168L))) + (c10::div_floor_integer((x2 + (64L*x1)), 4096L)))];
</span><span style="color:#183691;">                    auto tmp13 = out_ptr12[static_cast&lt;long&gt;(30L + (33L*x0) + (33L*(c10::div_floor_integer((122880L + x2 + (64L*x1)), 135168L))) + (c10::div_floor_integer((x2 + (64L*x1)), 4096L)))];
</span><span style="color:#183691;">                    auto tmp1 = (13L*x0) + (26L*(c10::div_floor_integer((x2 + (64L*x1)), 135168L)));
</span><span style="color:#183691;">                    auto tmp2 = c10::convert&lt;int64_t&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
</span><span style="color:#183691;">                    auto tmp4 = 156L;
</span><span style="color:#183691;">                    auto tmp5 = c10::convert&lt;int64_t&gt;(tmp4);
</span><span style="color:#183691;">                    auto tmp6 = decltype(tmp3)(tmp3 + tmp5);
</span><span style="color:#183691;">                    auto tmp7 = tmp3 &lt; 0;
</span><span style="color:#183691;">                    auto tmp8 = tmp7 ? tmp6 : tmp3;
</span><span style="color:#183691;">                    auto tmp9 = tmp8;
</span><span style="color:#183691;">                    auto tmp10 = c10::convert&lt;int64_t&gt;(tmp9);
</span><span style="color:#183691;">                    TORCH_CHECK((0 &lt;= tmp10) &amp; (tmp10 &lt; 156L), &quot;index out of bounds: 0 &lt;= tmp10 &lt; 156L&quot;);
</span><span style="color:#183691;">                    auto tmp12 = in_ptr13[static_cast&lt;long&gt;(x2 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp8, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x1) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp8) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                    auto tmp14 = (13L*x0) + (13L*(c10::div_floor_integer((30L + (c10::div_floor_integer((x2 + (64L*x1)), 4096L))), 33L))) + (13L*(c10::div_floor_integer((122880L + x2 + (64L*x1)), 135168L)));
</span><span style="color:#183691;">                    auto tmp15 = c10::convert&lt;int64_t&gt;(tmp14);
</span><span style="color:#183691;">                    auto tmp16 = decltype(tmp13)(tmp13 + tmp15);
</span><span style="color:#183691;">                    auto tmp17 = decltype(tmp16)(tmp16 + tmp5);
</span><span style="color:#183691;">                    auto tmp18 = tmp16 &lt; 0;
</span><span style="color:#183691;">                    auto tmp19 = tmp18 ? tmp17 : tmp16;
</span><span style="color:#183691;">                    auto tmp20 = tmp19;
</span><span style="color:#183691;">                    auto tmp21 = c10::convert&lt;int64_t&gt;(tmp20);
</span><span style="color:#183691;">                    TORCH_CHECK((0 &lt;= tmp21) &amp; (tmp21 &lt; 156L), &quot;index out of bounds: 0 &lt;= tmp21 &lt; 156L&quot;);
</span><span style="color:#183691;">                    auto tmp23 = in_ptr13[static_cast&lt;long&gt;(x2 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp19, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x1) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp19) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                    out_ptr19[static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0))] = tmp12;
</span><span style="color:#183691;">                    out_ptr20[static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0))] = tmp23;
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__softmax_add_cat_minimum_mul_new_ones_rsub_2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const int64_t* in_ptr2,
</span><span style="color:#183691;">                       const bfloat16* in_ptr3,
</span><span style="color:#183691;">                       const float* in_ptr4,
</span><span style="color:#183691;">                       const float* in_ptr5,
</span><span style="color:#183691;">                       const bfloat16* in_ptr6,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4,
</span><span style="color:#183691;">                       float* out_ptr5,
</span><span style="color:#183691;">                       float* out_ptr6,
</span><span style="color:#183691;">                       float* out_ptr7,
</span><span style="color:#183691;">                       float* out_ptr8,
</span><span style="color:#183691;">                       bfloat16* out_ptr9,
</span><span style="color:#183691;">                       bfloat16* out_ptr10,
</span><span style="color:#183691;">                       bfloat16* out_ptr11,
</span><span style="color:#183691;">                       bfloat16* out_ptr12,
</span><span style="color:#183691;">                       bfloat16* out_ptr13,
</span><span style="color:#183691;">                       bfloat16* out_ptr14,
</span><span style="color:#183691;">                       bfloat16* out_ptr15,
</span><span style="color:#183691;">                       bfloat16* out_ptr16,
</span><span style="color:#183691;">                       bfloat16* out_ptr17)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(192L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(64L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(768L + x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(192L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">            auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">            tmp1.store(out_ptr2 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(256L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                tmp1.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(192L); x2+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = in_ptr1[static_cast&lt;long&gt;(64L + x1)];
</span><span style="color:#183691;">                    auto tmp1 = in_ptr2[static_cast&lt;long&gt;((33L*x0) + (c10::div_floor_integer(x2, 64L)))];
</span><span style="color:#183691;">                    auto tmp12 = in_ptr1[static_cast&lt;long&gt;(704L + x1)];
</span><span style="color:#183691;">                    auto tmp13 = in_ptr2[static_cast&lt;long&gt;(30L + (33L*x0) + (c10::div_floor_integer(x2, 64L)))];
</span><span style="color:#183691;">                    auto tmp2 = 13L;
</span><span style="color:#183691;">                    auto tmp3 = c10::convert&lt;int64_t&gt;(tmp2);
</span><span style="color:#183691;">                    auto tmp4 = decltype(tmp1)(tmp1 + tmp3);
</span><span style="color:#183691;">                    auto tmp5 = tmp1 &lt; 0;
</span><span style="color:#183691;">                    auto tmp6 = tmp5 ? tmp4 : tmp1;
</span><span style="color:#183691;">                    auto tmp7 =
</span><span style="color:#183691;">                    [&amp;]
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        __at_align__ std::array&lt;int64_t, 16&gt; tmpbuf;
</span><span style="color:#183691;">                        #pragma GCC unroll 16
</span><span style="color:#183691;">                        for (long x2_inner = 0; x2_inner &lt; 16; x2_inner++)
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            tmpbuf[x2_inner] = static_cast&lt;long&gt;(tmp6);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                        return at::vec::VectorizedN&lt;int64_t,2&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    ()
</span><span style="color:#183691;">                    ;
</span><span style="color:#183691;">                    TORCH_CHECK((at::vec::VecMask&lt;int64_t,2&gt;((at::vec::VectorizedN&lt;int64_t,2&gt;(0) &lt;= tmp7) &amp; (tmp7 &lt; at::vec::VectorizedN&lt;int64_t,2&gt;(13L)))).all_masked(), &quot;index out of bounds: 0 &lt;= tmp7 &lt; 13L&quot;);
</span><span style="color:#183691;">                    auto tmp9 =
</span><span style="color:#183691;">                    [&amp;]
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        __at_align__ std::array&lt;float, 16&gt; tmpbuf;
</span><span style="color:#183691;">                        #pragma GCC unroll 16
</span><span style="color:#183691;">                        for (long x2_inner = 0; x2_inner &lt; 16; x2_inner++)
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            tmpbuf[x2_inner] = in_ptr1[static_cast&lt;long&gt;((64L*tmp6) + (static_cast&lt;long&gt;((x2 + x2_inner)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L)))];
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                        return at::vec::Vectorized&lt;float&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    ()
</span><span style="color:#183691;">                    ;
</span><span style="color:#183691;">                    auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                    auto tmp11 = tmp10 * tmp9;
</span><span style="color:#183691;">                    auto tmp14 = decltype(tmp13)(tmp13 + tmp3);
</span><span style="color:#183691;">                    auto tmp15 = tmp13 &lt; 0;
</span><span style="color:#183691;">                    auto tmp16 = tmp15 ? tmp14 : tmp13;
</span><span style="color:#183691;">                    auto tmp17 =
</span><span style="color:#183691;">                    [&amp;]
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        __at_align__ std::array&lt;int64_t, 16&gt; tmpbuf;
</span><span style="color:#183691;">                        #pragma GCC unroll 16
</span><span style="color:#183691;">                        for (long x2_inner = 0; x2_inner &lt; 16; x2_inner++)
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            tmpbuf[x2_inner] = static_cast&lt;long&gt;(tmp16);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                        return at::vec::VectorizedN&lt;int64_t,2&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    ()
</span><span style="color:#183691;">                    ;
</span><span style="color:#183691;">                    TORCH_CHECK((at::vec::VecMask&lt;int64_t,2&gt;((at::vec::VectorizedN&lt;int64_t,2&gt;(0) &lt;= tmp17) &amp; (tmp17 &lt; at::vec::VectorizedN&lt;int64_t,2&gt;(13L)))).all_masked(), &quot;index out of bounds: 0 &lt;= tmp17 &lt; 13L&quot;);
</span><span style="color:#183691;">                    auto tmp19 =
</span><span style="color:#183691;">                    [&amp;]
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        __at_align__ std::array&lt;float, 16&gt; tmpbuf;
</span><span style="color:#183691;">                        #pragma GCC unroll 16
</span><span style="color:#183691;">                        for (long x2_inner = 0; x2_inner &lt; 16; x2_inner++)
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            tmpbuf[x2_inner] = in_ptr1[static_cast&lt;long&gt;((64L*tmp16) + (static_cast&lt;long&gt;((x2 + x2_inner)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L)))];
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                        return at::vec::Vectorized&lt;float&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    ()
</span><span style="color:#183691;">                    ;
</span><span style="color:#183691;">                    auto tmp20 = at::vec::Vectorized&lt;float&gt;(tmp12);
</span><span style="color:#183691;">                    auto tmp21 = tmp20 * tmp19;
</span><span style="color:#183691;">                    tmp11.store(out_ptr4 + static_cast&lt;long&gt;(x2 + (448L*x1) + (28672L*x0)));
</span><span style="color:#183691;">                    tmp21.store(out_ptr5 + static_cast&lt;long&gt;(x2 + (448L*x1) + (28672L*x0)));
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = -std::numeric_limits&lt;float&gt;::infinity();
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(-std::numeric_limits&lt;float&gt;::infinity());
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp7 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr5 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::minimum(tmp6, tmp7);
</span><span style="color:#183691;">                        auto tmp9 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp9);
</span><span style="color:#183691;">                        auto tmp11 = tmp10 - tmp8;
</span><span style="color:#183691;">                        auto tmp12 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp13 = at::vec::Vectorized&lt;float&gt;(tmp12);
</span><span style="color:#183691;">                        auto tmp14 = tmp11 * tmp13;
</span><span style="color:#183691;">                        auto tmp15 = tmp5 + tmp14;
</span><span style="color:#183691;">                        tmp_acc0_vec = at::vec::maximum(tmp_acc0_vec, tmp15);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = max_propagate_nan(tmp_acc0, at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return at::vec::maximum(x, y); }, tmp_acc0_vec));
</span><span style="color:#183691;">                    out_ptr6[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = 0;
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(0);
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp7 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr5 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp16 = out_ptr6[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::minimum(tmp6, tmp7);
</span><span style="color:#183691;">                        auto tmp9 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp9);
</span><span style="color:#183691;">                        auto tmp11 = tmp10 - tmp8;
</span><span style="color:#183691;">                        auto tmp12 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp13 = at::vec::Vectorized&lt;float&gt;(tmp12);
</span><span style="color:#183691;">                        auto tmp14 = tmp11 * tmp13;
</span><span style="color:#183691;">                        auto tmp15 = tmp5 + tmp14;
</span><span style="color:#183691;">                        auto tmp17 = at::vec::Vectorized&lt;float&gt;(tmp16);
</span><span style="color:#183691;">                        auto tmp18 = tmp15 - tmp17;
</span><span style="color:#183691;">                        auto tmp19 = tmp18.exp();
</span><span style="color:#183691;">                        tmp19.store(out_ptr7 + static_cast&lt;long&gt;(x1 + (448L*x0)));
</span><span style="color:#183691;">                        tmp_acc0_vec = tmp_acc0_vec + tmp19;
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return x + y; }, tmp_acc0_vec);
</span><span style="color:#183691;">                    out_ptr8[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr7 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = out_ptr8[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">                    auto tmp4 = at::vec::convert&lt;bfloat16&gt;(tmp3);
</span><span style="color:#183691;">                    tmp4.store(out_ptr9 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr10 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr11 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(49152L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr12 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(98304L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr13 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(589824L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr14 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr15 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(192L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        #pragma GCC ivdep
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = in_ptr2[static_cast&lt;long&gt;((33L*x0) + (33L*(c10::div_floor_integer((x2 + (64L*x1)), 135168L))) + (c10::div_floor_integer((x2 + (64L*x1)), 4096L)))];
</span><span style="color:#183691;">                            auto tmp13 = in_ptr2[static_cast&lt;long&gt;(30L + (33L*x0) + (33L*(c10::div_floor_integer((122880L + x2 + (64L*x1)), 135168L))) + (c10::div_floor_integer((x2 + (64L*x1)), 4096L)))];
</span><span style="color:#183691;">                            auto tmp1 = (13L*x0) + (26L*(c10::div_floor_integer((x2 + (64L*x1)), 135168L)));
</span><span style="color:#183691;">                            auto tmp2 = c10::convert&lt;int64_t&gt;(tmp1);
</span><span style="color:#183691;">                            auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
</span><span style="color:#183691;">                            auto tmp4 = 156L;
</span><span style="color:#183691;">                            auto tmp5 = c10::convert&lt;int64_t&gt;(tmp4);
</span><span style="color:#183691;">                            auto tmp6 = decltype(tmp3)(tmp3 + tmp5);
</span><span style="color:#183691;">                            auto tmp7 = tmp3 &lt; 0;
</span><span style="color:#183691;">                            auto tmp8 = tmp7 ? tmp6 : tmp3;
</span><span style="color:#183691;">                            auto tmp9 = tmp8;
</span><span style="color:#183691;">                            auto tmp10 = c10::convert&lt;int64_t&gt;(tmp9);
</span><span style="color:#183691;">                            TORCH_CHECK((0 &lt;= tmp10) &amp; (tmp10 &lt; 156L), &quot;index out of bounds: 0 &lt;= tmp10 &lt; 156L&quot;);
</span><span style="color:#183691;">                            auto tmp12 = in_ptr6[static_cast&lt;long&gt;(x2 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp8, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x1) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp8) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                            auto tmp14 = (13L*x0) + (13L*(c10::div_floor_integer((30L + (c10::div_floor_integer((x2 + (64L*x1)), 4096L))), 33L))) + (13L*(c10::div_floor_integer((122880L + x2 + (64L*x1)), 135168L)));
</span><span style="color:#183691;">                            auto tmp15 = c10::convert&lt;int64_t&gt;(tmp14);
</span><span style="color:#183691;">                            auto tmp16 = decltype(tmp13)(tmp13 + tmp15);
</span><span style="color:#183691;">                            auto tmp17 = decltype(tmp16)(tmp16 + tmp5);
</span><span style="color:#183691;">                            auto tmp18 = tmp16 &lt; 0;
</span><span style="color:#183691;">                            auto tmp19 = tmp18 ? tmp17 : tmp16;
</span><span style="color:#183691;">                            auto tmp20 = tmp19;
</span><span style="color:#183691;">                            auto tmp21 = c10::convert&lt;int64_t&gt;(tmp20);
</span><span style="color:#183691;">                            TORCH_CHECK((0 &lt;= tmp21) &amp; (tmp21 &lt; 156L), &quot;index out of bounds: 0 &lt;= tmp21 &lt; 156L&quot;);
</span><span style="color:#183691;">                            auto tmp23 = in_ptr6[static_cast&lt;long&gt;(x2 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp19, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x1) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp19) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                            out_ptr16[static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0))] = tmp12;
</span><span style="color:#183691;">                            out_ptr17[static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0))] = tmp23;
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_cat_clone_3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       const bfloat16* in_ptr1,
</span><span style="color:#183691;">                       bfloat16* out_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr1,
</span><span style="color:#183691;">                       bfloat16* out_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr3)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(49152L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(98304L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(147456L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr2 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(576L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(98304L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                        tmp0.store(out_ptr3 + static_cast&lt;long&gt;(x2 + (64L*x1) + (36864L*x0)), 32);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_clone_4 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const int64_t* in_ptr0,
</span><span style="color:#183691;">                       const bfloat16* in_ptr1,
</span><span style="color:#183691;">                       const bfloat16* in_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr1)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(192L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        #pragma GCC ivdep
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = in_ptr0[static_cast&lt;long&gt;(3L + (3L*x1) + (33L*x0) + (33L*(c10::div_floor_integer((12288L + x3 + (64L*x2) + (12288L*x1)), 135168L))) + (c10::div_floor_integer((x3 + (64L*x2)), 4096L)))];
</span><span style="color:#183691;">                            auto tmp1 = (13L*x0) + (13L*(c10::div_floor_integer((3L + (3L*x1) + (c10::div_floor_integer((x3 + (64L*x2)), 4096L))), 33L))) + (13L*(c10::div_floor_integer((12288L + x3 + (64L*x2) + (12288L*x1)), 135168L)));
</span><span style="color:#183691;">                            auto tmp2 = c10::convert&lt;int64_t&gt;(tmp1);
</span><span style="color:#183691;">                            auto tmp3 = decltype(tmp0)(tmp0 + tmp2);
</span><span style="color:#183691;">                            auto tmp4 = 156L;
</span><span style="color:#183691;">                            auto tmp5 = c10::convert&lt;int64_t&gt;(tmp4);
</span><span style="color:#183691;">                            auto tmp6 = decltype(tmp3)(tmp3 + tmp5);
</span><span style="color:#183691;">                            auto tmp7 = tmp3 &lt; 0;
</span><span style="color:#183691;">                            auto tmp8 = tmp7 ? tmp6 : tmp3;
</span><span style="color:#183691;">                            auto tmp9 = tmp8;
</span><span style="color:#183691;">                            auto tmp10 = c10::convert&lt;int64_t&gt;(tmp9);
</span><span style="color:#183691;">                            TORCH_CHECK((0 &lt;= tmp10) &amp; (tmp10 &lt; 156L), &quot;index out of bounds: 0 &lt;= tmp10 &lt; 156L&quot;);
</span><span style="color:#183691;">                            auto tmp12 = in_ptr1[static_cast&lt;long&gt;(x3 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp8, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x2) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp8) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                            auto tmp13 = in_ptr2[static_cast&lt;long&gt;(x3 + (64L*(static_cast&lt;long&gt;(c10::div_floor_integer(tmp8, 13L)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(12L))) + (768L*(static_cast&lt;long&gt;(x2) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L))) + (49152L*(static_cast&lt;long&gt;(tmp8) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(13L))))];
</span><span style="color:#183691;">                            out_ptr0[static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0))] = tmp12;
</span><span style="color:#183691;">                            out_ptr1[static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0))] = tmp13;
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__softmax__to_copy_add_cat_mul_rsub_5 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const int64_t*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       const bfloat16* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       const bfloat16* in_ptr4,
</span><span style="color:#183691;">                       const float* in_ptr5,
</span><span style="color:#183691;">                       const int64_t* in_ptr6,
</span><span style="color:#183691;">                       const bfloat16* in_ptr7,
</span><span style="color:#183691;">                       const bfloat16* in_ptr8,
</span><span style="color:#183691;">                       const bfloat16* in_ptr9,
</span><span style="color:#183691;">                       bfloat16* out_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr1,
</span><span style="color:#183691;">                       bfloat16* out_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4,
</span><span style="color:#183691;">                       float* out_ptr5,
</span><span style="color:#183691;">                       float* out_ptr6,
</span><span style="color:#183691;">                       bfloat16* out_ptr7,
</span><span style="color:#183691;">                       bfloat16* out_ptr8,
</span><span style="color:#183691;">                       bfloat16* out_ptr9,
</span><span style="color:#183691;">                       bfloat16* out_ptr10)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(6912L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (64L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                    auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                    auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                    auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                    auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                    auto tmp5 = (tmp4);
</span><span style="color:#183691;">                    auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                    auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                    auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                    auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                    auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                    auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                    auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                    auto tmp14 = at::vec::convert&lt;bfloat16&gt;(tmp13);
</span><span style="color:#183691;">                    tmp14.store(out_ptr0 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(576L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(192L); x2+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr2 + static_cast&lt;long&gt;(x2 + (192L*x1) + (110592L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x2 + (192L*x1)), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                        auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                        auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                        auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                        auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                        auto tmp14 = at::vec::convert&lt;bfloat16&gt;(tmp13);
</span><span style="color:#183691;">                        tmp14.store(out_ptr1 + static_cast&lt;long&gt;(x2 + (512L*x1) + (294912L*x0)), 16);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(192L); x3+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(x3 + (192L*x2) + (12288L*x1) + (110592L*x0)), 16);
</span><span style="color:#183691;">                            auto tmp6 = in_ptr5[static_cast&lt;long&gt;(128L + x2 + (64L*x1))];
</span><span style="color:#183691;">                            auto tmp7 = in_ptr6[static_cast&lt;long&gt;(3L + (3L*x1) + (33L*x0) + (c10::div_floor_integer(x3, 64L)))];
</span><span style="color:#183691;">                            auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                            auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                            auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                            auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                            auto tmp5 = (tmp4);
</span><span style="color:#183691;">                            auto tmp8 = 13L;
</span><span style="color:#183691;">                            auto tmp9 = c10::convert&lt;int64_t&gt;(tmp8);
</span><span style="color:#183691;">                            auto tmp10 = decltype(tmp7)(tmp7 + tmp9);
</span><span style="color:#183691;">                            auto tmp11 = tmp7 &lt; 0;
</span><span style="color:#183691;">                            auto tmp12 = tmp11 ? tmp10 : tmp7;
</span><span style="color:#183691;">                            auto tmp13 =
</span><span style="color:#183691;">                            [&amp;]
</span><span style="color:#183691;">                            {
</span><span style="color:#183691;">                                __at_align__ std::array&lt;int64_t, 16&gt; tmpbuf;
</span><span style="color:#183691;">                                #pragma GCC unroll 16
</span><span style="color:#183691;">                                for (long x3_inner = 0; x3_inner &lt; 16; x3_inner++)
</span><span style="color:#183691;">                                {
</span><span style="color:#183691;">                                    tmpbuf[x3_inner] = static_cast&lt;long&gt;(tmp12);
</span><span style="color:#183691;">                                }
</span><span style="color:#183691;">                                return at::vec::VectorizedN&lt;int64_t,2&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                            }
</span><span style="color:#183691;">                            ()
</span><span style="color:#183691;">                            ;
</span><span style="color:#183691;">                            TORCH_CHECK((at::vec::VecMask&lt;int64_t,2&gt;((at::vec::VectorizedN&lt;int64_t,2&gt;(0) &lt;= tmp13) &amp; (tmp13 &lt; at::vec::VectorizedN&lt;int64_t,2&gt;(13L)))).all_masked(), &quot;index out of bounds: 0 &lt;= tmp13 &lt; 13L&quot;);
</span><span style="color:#183691;">                            auto tmp15 =
</span><span style="color:#183691;">                            [&amp;]
</span><span style="color:#183691;">                            {
</span><span style="color:#183691;">                                __at_align__ std::array&lt;float, 16&gt; tmpbuf;
</span><span style="color:#183691;">                                #pragma GCC unroll 16
</span><span style="color:#183691;">                                for (long x3_inner = 0; x3_inner &lt; 16; x3_inner++)
</span><span style="color:#183691;">                                {
</span><span style="color:#183691;">                                    tmpbuf[x3_inner] = in_ptr5[static_cast&lt;long&gt;((64L*tmp12) + (static_cast&lt;long&gt;((x3 + x3_inner)) </span><span style="color:#0086b3;">% s</span><span style="color:#183691;">tatic_cast&lt;long&gt;(64L)))];
</span><span style="color:#183691;">                                }
</span><span style="color:#183691;">                                return at::vec::Vectorized&lt;float&gt;::loadu(tmpbuf.data(), 16);
</span><span style="color:#183691;">                            }
</span><span style="color:#183691;">                            ()
</span><span style="color:#183691;">                            ;
</span><span style="color:#183691;">                            auto tmp16 = at::vec::Vectorized&lt;float&gt;(tmp6);
</span><span style="color:#183691;">                            auto tmp17 = tmp16 * tmp15;
</span><span style="color:#183691;">                            auto tmp18 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                            auto tmp19 = at::vec::Vectorized&lt;float&gt;(tmp18);
</span><span style="color:#183691;">                            auto tmp20 = tmp19 - tmp17;
</span><span style="color:#183691;">                            auto tmp21 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                            auto tmp22 = at::vec::Vectorized&lt;float&gt;(tmp21);
</span><span style="color:#183691;">                            auto tmp23 = tmp20 * tmp22;
</span><span style="color:#183691;">                            auto tmp24 = tmp5 + tmp23;
</span><span style="color:#183691;">                            auto tmp25 = at::vec::convert&lt;bfloat16&gt;(tmp24);
</span><span style="color:#183691;">                            tmp25.store(out_ptr2 + static_cast&lt;long&gt;(x3 + (512L*x2) + (32768L*x1) + (294912L*x0)), 16);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(6912L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr7 + static_cast&lt;long&gt;(x1 + (64L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(768L + x1), 16);
</span><span style="color:#183691;">                    auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                    auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                    auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                    auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                    auto tmp5 = (tmp4);
</span><span style="color:#183691;">                    auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                    auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                    auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                    auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                    auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                    auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                    auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                    auto tmp14 = at::vec::convert&lt;bfloat16&gt;(tmp13);
</span><span style="color:#183691;">                    tmp14.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(6912L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = -std::numeric_limits&lt;float&gt;::infinity();
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(-std::numeric_limits&lt;float&gt;::infinity());
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(512L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr8 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        tmp_acc0_vec = at::vec::maximum(tmp_acc0_vec, tmp1);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = max_propagate_nan(tmp_acc0, at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return at::vec::maximum(x, y); }, tmp_acc0_vec));
</span><span style="color:#183691;">                    out_ptr4[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = 0;
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(0);
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(512L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr8 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp2 = out_ptr4[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 - tmp3;
</span><span style="color:#183691;">                        auto tmp5 = tmp4.exp();
</span><span style="color:#183691;">                        tmp5.store(out_ptr5 + static_cast&lt;long&gt;(x1 + (512L*x0)));
</span><span style="color:#183691;">                        tmp_acc0_vec = tmp_acc0_vec + tmp5;
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return x + y; }, tmp_acc0_vec);
</span><span style="color:#183691;">                    out_ptr6[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(512L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr5 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = out_ptr6[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">                    auto tmp4 = at::vec::convert&lt;bfloat16&gt;(tmp3);
</span><span style="color:#183691;">                    tmp4.store(out_ptr7 + static_cast&lt;long&gt;(x1 + (512L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr9 + static_cast&lt;long&gt;(49152L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr8 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr9 + static_cast&lt;long&gt;(98304L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr9 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(9L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x3=static_cast&lt;long&gt;(0L); x3&lt;static_cast&lt;long&gt;(64L); x3+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr9 + static_cast&lt;long&gt;(147456L + x3 + (64L*x0) + (768L*x2) + (49152L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr10 + static_cast&lt;long&gt;(x3 + (64L*x2) + (12288L*x1) + (110592L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_cat_6 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr1)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(491520L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma GCC ivdep
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(540672L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                    tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__softmax_add_cat_minimum_mul_rsub_7 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const float* in_ptr0,
</span><span style="color:#183691;">                       const bfloat16* in_ptr1,
</span><span style="color:#183691;">                       const float* in_ptr2,
</span><span style="color:#183691;">                       const float* in_ptr3,
</span><span style="color:#183691;">                       const bfloat16* in_ptr4,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       float* out_ptr3,
</span><span style="color:#183691;">                       float* out_ptr4,
</span><span style="color:#183691;">                       float* out_ptr5,
</span><span style="color:#183691;">                       float* out_ptr6,
</span><span style="color:#183691;">                       bfloat16* out_ptr7,
</span><span style="color:#183691;">                       bfloat16* out_ptr8,
</span><span style="color:#183691;">                       bfloat16* out_ptr9)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(64L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(192L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(640L + x0), 16);
</span><span style="color:#183691;">            tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(192L); x0+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            auto tmp0 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">            auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">            tmp1.store(out_ptr2 + static_cast&lt;long&gt;(x0));
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(256L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                auto tmp1 = at::vec::Vectorized&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                tmp1.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)));
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = -std::numeric_limits&lt;float&gt;::infinity();
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(-std::numeric_limits&lt;float&gt;::infinity());
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp7 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::minimum(tmp6, tmp7);
</span><span style="color:#183691;">                        auto tmp9 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp9);
</span><span style="color:#183691;">                        auto tmp11 = tmp10 - tmp8;
</span><span style="color:#183691;">                        auto tmp12 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp13 = at::vec::Vectorized&lt;float&gt;(tmp12);
</span><span style="color:#183691;">                        auto tmp14 = tmp11 * tmp13;
</span><span style="color:#183691;">                        auto tmp15 = tmp5 + tmp14;
</span><span style="color:#183691;">                        tmp_acc0_vec = at::vec::maximum(tmp_acc0_vec, tmp15);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = max_propagate_nan(tmp_acc0, at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return at::vec::maximum(x, y); }, tmp_acc0_vec));
</span><span style="color:#183691;">                    out_ptr4[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = 0;
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(0);
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr2 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp7 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp16 = out_ptr4[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::minimum(tmp6, tmp7);
</span><span style="color:#183691;">                        auto tmp9 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp10 = at::vec::Vectorized&lt;float&gt;(tmp9);
</span><span style="color:#183691;">                        auto tmp11 = tmp10 - tmp8;
</span><span style="color:#183691;">                        auto tmp12 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp13 = at::vec::Vectorized&lt;float&gt;(tmp12);
</span><span style="color:#183691;">                        auto tmp14 = tmp11 * tmp13;
</span><span style="color:#183691;">                        auto tmp15 = tmp5 + tmp14;
</span><span style="color:#183691;">                        auto tmp17 = at::vec::Vectorized&lt;float&gt;(tmp16);
</span><span style="color:#183691;">                        auto tmp18 = tmp15 - tmp17;
</span><span style="color:#183691;">                        auto tmp19 = tmp18.exp();
</span><span style="color:#183691;">                        tmp19.store(out_ptr5 + static_cast&lt;long&gt;(x1 + (448L*x0)));
</span><span style="color:#183691;">                        tmp_acc0_vec = tmp_acc0_vec + tmp19;
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return x + y; }, tmp_acc0_vec);
</span><span style="color:#183691;">                    out_ptr6[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(448L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr5 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = out_ptr6[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">                    auto tmp4 = at::vec::convert&lt;bfloat16&gt;(tmp3);
</span><span style="color:#183691;">                    tmp4.store(out_ptr7 + static_cast&lt;long&gt;(x1 + (448L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(491520L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr8 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    #pragma GCC ivdep
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(64L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                        {
</span><span style="color:#183691;">                            auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(540672L + x2 + (64L*x0) + (768L*x1)), 32);
</span><span style="color:#183691;">                            tmp0.store(out_ptr9 + static_cast&lt;long&gt;(x2 + (64L*x1) + (28672L*x0)), 32);
</span><span style="color:#183691;">                        }
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused__softmax_add_mul_rsub_8 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       const float* in_ptr1,
</span><span style="color:#183691;">                       float* out_ptr0,
</span><span style="color:#183691;">                       float* out_ptr1,
</span><span style="color:#183691;">                       float* out_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr3)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(768L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = -std::numeric_limits&lt;float&gt;::infinity();
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(-std::numeric_limits&lt;float&gt;::infinity());
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                        auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                        auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                        auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                        auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                        tmp_acc0_vec = at::vec::maximum(tmp_acc0_vec, tmp13);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = max_propagate_nan(tmp_acc0, at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return at::vec::maximum(x, y); }, tmp_acc0_vec));
</span><span style="color:#183691;">                    out_ptr0[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    float tmp_acc0 = 0;
</span><span style="color:#183691;">                    at::vec::Vectorized&lt;float&gt; tmp_acc0_vec = at::vec::Vectorized&lt;float&gt;(0);
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp6 = at::vec::Vectorized&lt;float&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1), 16);
</span><span style="color:#183691;">                        auto tmp14 = out_ptr0[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp2 = static_cast&lt;float&gt;(0.125);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        auto tmp5 = (tmp4);
</span><span style="color:#183691;">                        auto tmp7 = static_cast&lt;float&gt;(1.0);
</span><span style="color:#183691;">                        auto tmp8 = at::vec::Vectorized&lt;float&gt;(tmp7);
</span><span style="color:#183691;">                        auto tmp9 = tmp8 - tmp6;
</span><span style="color:#183691;">                        auto tmp10 = static_cast&lt;float&gt;(-10000.0);
</span><span style="color:#183691;">                        auto tmp11 = at::vec::Vectorized&lt;float&gt;(tmp10);
</span><span style="color:#183691;">                        auto tmp12 = tmp9 * tmp11;
</span><span style="color:#183691;">                        auto tmp13 = tmp5 + tmp12;
</span><span style="color:#183691;">                        auto tmp15 = at::vec::Vectorized&lt;float&gt;(tmp14);
</span><span style="color:#183691;">                        auto tmp16 = tmp13 - tmp15;
</span><span style="color:#183691;">                        auto tmp17 = tmp16.exp();
</span><span style="color:#183691;">                        tmp17.store(out_ptr1 + static_cast&lt;long&gt;(x1 + (832L*x0)));
</span><span style="color:#183691;">                        tmp_acc0_vec = tmp_acc0_vec + tmp17;
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                    tmp_acc0 = tmp_acc0 + at::vec::vec_reduce_all&lt;float&gt;([](at::vec::Vectorized&lt;float&gt;&amp; x, at::vec::Vectorized&lt;float&gt;&amp; y) { return x + y; }, tmp_acc0_vec);
</span><span style="color:#183691;">                    out_ptr2[static_cast&lt;long&gt;(x0)] = static_cast&lt;float&gt;(tmp_acc0);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;float&gt;::loadu(out_ptr1 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = out_ptr2[static_cast&lt;long&gt;(x0)];
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;float&gt;(tmp1);
</span><span style="color:#183691;">                    auto tmp3 = tmp0 / tmp2;
</span><span style="color:#183691;">                    auto tmp4 = at::vec::convert&lt;bfloat16&gt;(tmp3);
</span><span style="color:#183691;">                    tmp4.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (832L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">cpp_fused_cat_mul_9 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">async_compile.cpp_pybinding([</span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;const float*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;bfloat16*&#39;</span><span style="color:#323232;">, </span><span style="color:#183691;">&#39;float*&#39;</span><span style="color:#323232;">], </span><span style="color:#183691;">&#39;&#39;&#39;
</span><span style="color:#183691;">#include &quot;/tmp/torchinductor_leslie/sk/cskh5dx62fglpphcrl6723dnmowdabouerrzy3dmqcngbxwfa7bv.h&quot;
</span><span style="color:#183691;">extern &quot;C&quot; void kernel(const bfloat16* in_ptr0,
</span><span style="color:#183691;">                       const bfloat16* in_ptr1,
</span><span style="color:#183691;">                       const bfloat16* in_ptr2,
</span><span style="color:#183691;">                       const bfloat16* in_ptr3,
</span><span style="color:#183691;">                       const bfloat16* in_ptr4,
</span><span style="color:#183691;">                       const bfloat16* in_ptr5,
</span><span style="color:#183691;">                       const bfloat16* in_ptr6,
</span><span style="color:#183691;">                       const bfloat16* in_ptr7,
</span><span style="color:#183691;">                       const bfloat16* in_ptr8,
</span><span style="color:#183691;">                       const float* in_ptr9,
</span><span style="color:#183691;">                       bfloat16* out_ptr0,
</span><span style="color:#183691;">                       bfloat16* out_ptr1,
</span><span style="color:#183691;">                       bfloat16* out_ptr2,
</span><span style="color:#183691;">                       bfloat16* out_ptr3,
</span><span style="color:#183691;">                       bfloat16* out_ptr4,
</span><span style="color:#183691;">                       float* out_ptr5)
</span><span style="color:#183691;">{
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(4096L); x1+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr0 + static_cast&lt;long&gt;(x1 + (4096L*x0)), 32);
</span><span style="color:#183691;">                tmp0.store(out_ptr0 + static_cast&lt;long&gt;(x1 + (53248L*x0)), 32);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        #pragma GCC ivdep
</span><span style="color:#183691;">        for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(4096L); x1+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr1 + static_cast&lt;long&gt;(x1 + (4096L*x0)), 32);
</span><span style="color:#183691;">                tmp0.store(out_ptr1 + static_cast&lt;long&gt;(x1 + (53248L*x0)), 32);
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">    #pragma omp parallel num_threads(56)
</span><span style="color:#183691;">    {
</span><span style="color:#183691;">        int tid = omp_get_thread_num();
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(36864L); x1+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr2 + static_cast&lt;long&gt;(x1 + (36864L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp2 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr3 + static_cast&lt;long&gt;(x1 + (36864L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp5 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr4 + static_cast&lt;long&gt;(x1 + (36864L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp8 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr5 + static_cast&lt;long&gt;(x1 + (36864L*x0)), 16);
</span><span style="color:#183691;">                    auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                    auto tmp3 = at::vec::convert&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                    auto tmp4 = tmp1 + tmp3;
</span><span style="color:#183691;">                    auto tmp6 = at::vec::convert&lt;float&gt;(tmp5);
</span><span style="color:#183691;">                    auto tmp7 = tmp4 + tmp6;
</span><span style="color:#183691;">                    auto tmp9 = at::vec::convert&lt;float&gt;(tmp8);
</span><span style="color:#183691;">                    auto tmp10 = tmp7 + tmp9;
</span><span style="color:#183691;">                    auto tmp11 = at::vec::convert&lt;bfloat16&gt;(tmp10);
</span><span style="color:#183691;">                    tmp11.store(out_ptr2 + static_cast&lt;long&gt;(x1 + (53248L*x0)), 16);
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(4096L); x1+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr6 + static_cast&lt;long&gt;(x1 + (4096L*x0)), 32);
</span><span style="color:#183691;">                        tmp0.store(out_ptr3 + static_cast&lt;long&gt;(x1 + (53248L*x0)), 32);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        #pragma omp single
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(4096L); x1+=static_cast&lt;long&gt;(32L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr7 + static_cast&lt;long&gt;(x1 + (4096L*x0)), 32);
</span><span style="color:#183691;">                        tmp0.store(out_ptr4 + static_cast&lt;long&gt;(x1 + (53248L*x0)), 32);
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">        {
</span><span style="color:#183691;">            #pragma omp for
</span><span style="color:#183691;">            for(long x0=static_cast&lt;long&gt;(0L); x0&lt;static_cast&lt;long&gt;(12L); x0+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">            {
</span><span style="color:#183691;">                #pragma GCC ivdep
</span><span style="color:#183691;">                for(long x1=static_cast&lt;long&gt;(0L); x1&lt;static_cast&lt;long&gt;(832L); x1+=static_cast&lt;long&gt;(1L))
</span><span style="color:#183691;">                {
</span><span style="color:#183691;">                    for(long x2=static_cast&lt;long&gt;(0L); x2&lt;static_cast&lt;long&gt;(64L); x2+=static_cast&lt;long&gt;(16L))
</span><span style="color:#183691;">                    {
</span><span style="color:#183691;">                        auto tmp0 = at::vec::Vectorized&lt;bfloat16&gt;::loadu(in_ptr8 + static_cast&lt;long&gt;(x2 + (64L*x1) + (53248L*x0)), 16);
</span><span style="color:#183691;">                        auto tmp2 = in_ptr9[static_cast&lt;long&gt;(x1)];
</span><span style="color:#183691;">                        auto tmp1 = at::vec::convert&lt;float&gt;(tmp0);
</span><span style="color:#183691;">                        auto tmp3 = at::vec::Vectorized&lt;float&gt;(tmp2);
</span><span style="color:#183691;">                        auto tmp4 = tmp1 * tmp3;
</span><span style="color:#183691;">                        tmp4.store(out_ptr5 + static_cast&lt;long&gt;(x2 + (64L*x1) + (53248L*x0)));
</span><span style="color:#183691;">                    }
</span><span style="color:#183691;">                }
</span><span style="color:#183691;">            }
</span><span style="color:#183691;">        }
</span><span style="color:#183691;">    }
</span><span style="color:#183691;">}
</span><span style="color:#183691;">&#39;&#39;&#39;</span><span style="color:#323232;">)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="color:#323232;">async_compile.wait(</span><span style="color:#62a35c;">globals</span><span style="color:#323232;">())
</span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">async_compile
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">call</span><span style="color:#323232;">(args):
</span><span style="color:#323232;">    arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">args
</span><span style="color:#323232;">    args.clear()
</span><span style="color:#323232;">    assert_size_stride(arg0_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg1_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg2_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg3_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg4_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg5_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg6_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg7_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg8_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg9_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg10_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg11_1, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg12_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg13_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">13</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg14_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg15_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg16_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg17_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    assert_size_stride(arg18_1, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">))
</span><span style="color:#323232;">    buf0 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(arg14_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf0)
</span><span style="color:#323232;">    buf1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf2 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf3 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf4 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    cpp_fused__softmax_add_mul_rsub_0(buf0, arg16_1, buf1, buf2, buf3, buf4)
</span><span style="color:#323232;">    buf5 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_1], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf4, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(arg15_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf5)
</span><span style="color:#323232;">    buf18 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">132</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.int32)
</span><span style="color:#323232;">    buf6 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf7 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">33</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf8 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">66</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf9 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">99</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf10 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">132</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf11 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">165</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf12 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">198</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf13 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">231</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf14 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">264</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf15 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">297</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf16 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">330</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf17 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf18, (</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">363</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf19 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">33</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.int64)
</span><span style="color:#323232;">    buf25 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf20 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf78 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf73 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf21 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf22 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf23 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf76 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf24 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">16384</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf77 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">16384</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    cpp_fused__to_copy_cat_stack_1(arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, buf18, arg14_1, buf6, buf7, buf8, buf9, buf10, buf11, buf12, buf13, buf14, buf15, buf16, buf17, buf19, buf20, buf73, buf21, buf22, buf23, buf76, buf24, buf77)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg0_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg10_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg11_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg1_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg2_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg3_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg4_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg5_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg6_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg7_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg8_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg9_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf10
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf11
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf12
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf13
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf14
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf15
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf16
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf17
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf18
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf20
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf21
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf22
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf23
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf24
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf6
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf7
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf8
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf9
</span><span style="color:#323232;">    buf26 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_2], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">49152</span><span style="color:#323232;">), reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf26)
</span><span style="color:#323232;">    buf30 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf27 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf30, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf28 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf30, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf29 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf30, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf33 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf31 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf33, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">256</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf32 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf33, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf86 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf85 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf86, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf34 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf3; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf3  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf35 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf36 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf1; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf1  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf43 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf25, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf25  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf42 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf37 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf95 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf90 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf38 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf39 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf40 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf93 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf41 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">16384</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf94 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">16384</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    cpp_fused__softmax_add_cat_minimum_mul_new_ones_rsub_2(arg16_1, arg13_1, buf19, buf26, buf30, buf33, arg15_1, buf27, buf28, buf29, buf31, buf32, buf85, buf34, buf35, buf36, buf43, buf37, buf90, buf38, buf39, buf40, buf93, buf41, buf94)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf26
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf27
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf28
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf29
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf31
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf32
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf33
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf37
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf38
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf39
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf40
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf41
</span><span style="color:#323232;">    buf44 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_3], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf43, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf42, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf44)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf42
</span><span style="color:#323232;">    buf45 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">36864</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [first_band_product], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">98304</span><span style="color:#323232;">), reinterpret_tensor(arg14_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf45)
</span><span style="color:#323232;">    buf49 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf46 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf49, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf47 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf49, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf48 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf49, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf50 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">442368</span><span style="color:#323232;">, </span><span style="color:#0086b3;">36864</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    cpp_fused_cat_clone_3(arg14_1, arg12_1, buf46, buf47, buf48, buf50)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf46
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf47
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf48
</span><span style="color:#323232;">    buf51 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_4], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf50, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf49, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf51)
</span><span style="color:#323232;">    buf52 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf49; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf49  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf69 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    cpp_fused_clone_4(buf19, arg14_1, arg15_1, buf52, buf69)
</span><span style="color:#323232;">    buf53 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_5], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf50, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf52, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf53)
</span><span style="color:#323232;">    buf54 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf50, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">36864</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf50  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [last_band_product], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">98304</span><span style="color:#323232;">), reinterpret_tensor(arg14_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), </span><span style="color:#0086b3;">589824</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf54)
</span><span style="color:#323232;">    buf59 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf55 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf59, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf56 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf59, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">64</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf57 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf59, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf58 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf59, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">448</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf60 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">6912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">6912</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf61 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf62 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">6912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">6912</span><span style="color:#323232;">), torch.float32)
</span><span style="color:#323232;">    buf67 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3538944</span><span style="color:#323232;">, </span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    buf66 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf52; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf52  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf63 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf66, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf64 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf66, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf65 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf66, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">1327104</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    cpp_fused__softmax__to_copy_add_cat_mul_rsub_5(buf45, arg16_1, buf51, arg17_1, buf53, arg13_1, buf19, buf54, buf59, arg15_1, buf55, buf56, buf57, buf58, buf60, buf61, buf62, buf67, buf63, buf64, buf65)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg13_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg17_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf51
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf53
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf55
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf56
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf57
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf58
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf59
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf60
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf61
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf62
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf63
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf64
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf65
</span><span style="color:#323232;">    buf68 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf54, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf54  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_6], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf67, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), reinterpret_tensor(buf66, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf68)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf66
</span><span style="color:#323232;">    buf70 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf45, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf45  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_7], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf67, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">32768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">), reinterpret_tensor(buf69, (</span><span style="color:#0086b3;">108</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf70)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf69
</span><span style="color:#323232;">    buf71 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">36864</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [einsum_3], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf67, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(arg15_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf71)
</span><span style="color:#323232;">    buf72 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">36864</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [einsum_4], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf67, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">576</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">294912</span><span style="color:#323232;">, </span><span style="color:#0086b3;">512</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), reinterpret_tensor(arg15_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">589824</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf72)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf67
</span><span style="color:#323232;">    buf74 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf75 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    cpp_fused_cat_6(arg14_1, buf74, buf75)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf73
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf74
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf75
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf76
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf77
</span><span style="color:#323232;">    buf79 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf43, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf43  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_8], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">540672</span><span style="color:#323232;">), reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf79)
</span><span style="color:#323232;">    buf83 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf30; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf30  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf80 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf83, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf81 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf83, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">64</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf82 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf83, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">256</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf84 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf86, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">256</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf87 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf36; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf36  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf88 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf35; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf35  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf89 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf34; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf34  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf96 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf78, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf78  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf91 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf92 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">344064</span><span style="color:#323232;">, </span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    cpp_fused__softmax_add_cat_minimum_mul_rsub_7(arg16_1, buf79, buf83, buf86, arg15_1, buf80, buf81, buf82, buf84, buf87, buf88, buf89, buf96, buf91, buf92)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf79
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf80
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf81
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf82
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf83
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf84
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf85
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf86
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf88
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf90
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf91
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf92
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf93
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf94
</span><span style="color:#323232;">    buf97 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_9], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf96, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf95, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">448</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">28672</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf97)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf95
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf96
</span><span style="color:#323232;">    buf98 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf4, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf4  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_10], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(arg12_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">589824</span><span style="color:#323232;">), reinterpret_tensor(arg14_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf98)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg12_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg14_1
</span><span style="color:#323232;">    buf99 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf89; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf89  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf100 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf2; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf2  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf101 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">buf87; </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf87  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf102 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf0, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf0  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    cpp_fused__softmax_add_mul_rsub_8(buf98, arg16_1, buf99, buf100, buf101, buf102)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg16_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf101
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf98
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf99
</span><span style="color:#323232;">    buf103 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">empty_strided_cpu((</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), torch.bfloat16)
</span><span style="color:#323232;">    </span><span style="font-style:italic;color:#969896;"># Source Nodes: [bmm_11], Original ATen: [aten.bmm]
</span><span style="color:#323232;">    extern_kernels.bmm(reinterpret_tensor(buf102, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(arg15_1, (</span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), out</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">buf103)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg15_1
</span><span style="color:#323232;">    buf109 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf102, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">13</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf102  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    buf104 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf109, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf105 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf109, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf106 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf109, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">8192</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf107 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf109, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">45056</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf108 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf109, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">4096</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">49152</span><span style="color:#323232;">)  </span><span style="font-style:italic;color:#969896;"># alias
</span><span style="color:#323232;">    buf110 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">reinterpret_tensor(buf100, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">); </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">buf100  </span><span style="font-style:italic;color:#969896;"># reuse
</span><span style="color:#323232;">    cpp_fused_cat_mul_9(buf5, buf44, buf68, buf70, buf71, buf72, buf97, buf103, buf109, arg18_1, buf104, buf105, buf106, buf107, buf108, buf110)
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">del </span><span style="color:#323232;">arg18_1
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">(reinterpret_tensor(buf110, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">53248</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), reinterpret_tensor(buf19, (</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">396</span><span style="color:#323232;">, </span><span style="color:#0086b3;">33</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), </span><span style="color:#0086b3;">0</span><span style="color:#323232;">), )
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">def </span><span style="font-weight:bold;color:#323232;">benchmark_compiled_module</span><span style="color:#323232;">(times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#0086b3;">10</span><span style="color:#323232;">):
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._dynamo.testing </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">rand_strided
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.utils </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">print_performance
</span><span style="color:#323232;">    arg0_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg1_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg2_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg3_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg4_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg5_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg6_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg7_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg8_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg9_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg10_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg11_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">11</span><span style="color:#323232;">, </span><span style="color:#0086b3;">3</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">3</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.int32)
</span><span style="color:#323232;">    arg12_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.bfloat16)
</span><span style="color:#323232;">    arg13_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">13</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    arg14_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.bfloat16)
</span><span style="color:#323232;">    arg15_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">638976</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">768</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.bfloat16)
</span><span style="color:#323232;">    arg16_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    arg17_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">9</span><span style="color:#323232;">, </span><span style="color:#0086b3;">64</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">110592</span><span style="color:#323232;">, </span><span style="color:#0086b3;">12288</span><span style="color:#323232;">, </span><span style="color:#0086b3;">192</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    arg18_1 </span><span style="font-weight:bold;color:#a71d5d;">= </span><span style="color:#323232;">rand_strided((</span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), (</span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">832</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">, </span><span style="color:#0086b3;">1</span><span style="color:#323232;">), device</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#183691;">&#39;cpu&#39;</span><span style="color:#323232;">, dtype</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">torch.float32)
</span><span style="color:#323232;">    fn </span><span style="font-weight:bold;color:#a71d5d;">= lambda</span><span style="color:#323232;">: call([arg0_1, arg1_1, arg2_1, arg3_1, arg4_1, arg5_1, arg6_1, arg7_1, arg8_1, arg9_1, arg10_1, arg11_1, arg12_1, arg13_1, arg14_1, arg15_1, arg16_1, arg17_1, arg18_1])
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">return </span><span style="color:#323232;">print_performance(fn, times</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">times, repeat</span><span style="font-weight:bold;color:#a71d5d;">=</span><span style="color:#323232;">repeat)
</span><span style="color:#323232;">
</span><span style="color:#323232;">
</span><span style="font-weight:bold;color:#a71d5d;">if </span><span style="color:#323232;">__name__ </span><span style="font-weight:bold;color:#a71d5d;">== </span><span style="color:#183691;">&quot;__main__&quot;</span><span style="color:#323232;">:
</span><span style="color:#323232;">    </span><span style="font-weight:bold;color:#a71d5d;">from </span><span style="color:#323232;">torch._inductor.wrapper_benchmark </span><span style="font-weight:bold;color:#a71d5d;">import </span><span style="color:#323232;">compiled_module_main
</span><span style="color:#323232;">    compiled_module_main(</span><span style="color:#183691;">&#39;hf_BigBird&#39;</span><span style="color:#323232;">, benchmark_compiled_module)
</span></pre>
