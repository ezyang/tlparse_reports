class GraphModule(torch.nn.Module):
    def forward(self, L_stack0_0_: "i32[11, 3][3, 1]cpu", L_stack0_1_: "i32[11, 3][3, 1]cpu", L_stack0_2_: "i32[11, 3][3, 1]cpu", L_stack0_3_: "i32[11, 3][3, 1]cpu", L_stack0_4_: "i32[11, 3][3, 1]cpu", L_stack0_5_: "i32[11, 3][3, 1]cpu", L_stack0_6_: "i32[11, 3][3, 1]cpu", L_stack0_7_: "i32[11, 3][3, 1]cpu", L_stack0_8_: "i32[11, 3][3, 1]cpu", L_stack0_9_: "i32[11, 3][3, 1]cpu", L_stack0_10_: "i32[11, 3][3, 1]cpu", L_stack0_11_: "i32[11, 3][3, 1]cpu", L_query_layer_: "bf16[1, 12, 832, 64][638976, 64, 768, 1]cpu", L_from_blocked_mask_: "f32[1, 13, 64][832, 64, 1]cpu", L_key_layer_: "bf16[1, 12, 832, 64][638976, 64, 768, 1]cpu", L_value_layer_: "bf16[1, 12, 832, 64][638976, 64, 768, 1]cpu", L_to_mask_: "f32[1, 1, 1, 832][832, 832, 832, 1]cpu", L_band_mask_: "f32[1, 1, 9, 64, 192][110592, 110592, 12288, 192, 1]cpu", L_from_mask_: "f32[1, 1, 832, 1][832, 832, 1, 1]cpu"):
        l_stack0_0_ = L_stack0_0_
        l_stack0_1_ = L_stack0_1_
        l_stack0_2_ = L_stack0_2_
        l_stack0_3_ = L_stack0_3_
        l_stack0_4_ = L_stack0_4_
        l_stack0_5_ = L_stack0_5_
        l_stack0_6_ = L_stack0_6_
        l_stack0_7_ = L_stack0_7_
        l_stack0_8_ = L_stack0_8_
        l_stack0_9_ = L_stack0_9_
        l_stack0_10_ = L_stack0_10_
        l_stack0_11_ = L_stack0_11_
        l_query_layer_ = L_query_layer_
        l_from_blocked_mask_ = L_from_blocked_mask_
        l_key_layer_ = L_key_layer_
        l_value_layer_ = L_value_layer_
        l_to_mask_ = L_to_mask_
        l_band_mask_ = L_band_mask_
        l_from_mask_ = L_from_mask_
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:593 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_attn = np.stack(rand_attn, axis=0)
        rand_attn: "i32[12, 11, 3][33, 3, 1]cpu" = torch__dynamo_utils_wrapped_stack([l_stack0_0_, l_stack0_1_, l_stack0_2_, l_stack0_3_, l_stack0_4_, l_stack0_5_, l_stack0_6_, l_stack0_7_, l_stack0_8_, l_stack0_9_, l_stack0_10_, l_stack0_11_], axis = 0);  l_stack0_0_ = l_stack0_1_ = l_stack0_2_ = l_stack0_3_ = l_stack0_4_ = l_stack0_5_ = l_stack0_6_ = l_stack0_7_ = l_stack0_8_ = l_stack0_9_ = l_stack0_10_ = l_stack0_11_ = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:594 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_attn = torch.tensor(rand_attn, device=query_layer.device, dtype=torch.long)
        rand_attn_1: "i64[1, 12, 11, 3][396, 33, 3, 1]cpu" = torch.tensor(rand_attn, device = device(type='cpu'), dtype = torch.int64);  rand_attn = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:595 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_attn.unsqueeze_(0)
        unsqueeze_: "i64[1, 12, 11, 3][396, 33, 3, 1]cpu" = rand_attn_1.unsqueeze_(0)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:596 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_attn = torch.cat([rand_attn for _ in range(batch_size)], dim=0)
        rand_attn_2: "i64[1, 12, 11, 3][396, 33, 3, 1]cpu" = torch.cat([rand_attn_1], dim = 0);  rand_attn_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1015 in _create_rand_mask_from_inputs, code: rand_mask = torch.stack([p1[i1.flatten()] for p1, i1 in zip(to_blocked_mask, rand_attn)])
        p1: "f32[13, 64][64, 1]cpu" = l_from_blocked_mask_[0]
        i1: "i64[12, 11, 3][33, 3, 1]cpu" = rand_attn_2[0]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1015 in <listcomp>, code: rand_mask = torch.stack([p1[i1.flatten()] for p1, i1 in zip(to_blocked_mask, rand_attn)])
        flatten: "i64[396][1]cpu" = i1.flatten();  i1 = None
        getitem_2: "f32[396, 64][64, 1]cpu" = p1[flatten];  p1 = flatten = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1015 in _create_rand_mask_from_inputs, code: rand_mask = torch.stack([p1[i1.flatten()] for p1, i1 in zip(to_blocked_mask, rand_attn)])
        rand_mask: "f32[1, 396, 64][25344, 64, 1]cpu" = torch.stack([getitem_2]);  getitem_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1016 in _create_rand_mask_from_inputs, code: rand_mask = rand_mask.view(batch_size, num_attention_heads, num_windows, num_rand_blocks * from_block_size)
        rand_mask_1: "f32[1, 12, 11, 192][25344, 2112, 192, 1]cpu" = rand_mask.view(1, 12, 11, 192);  rand_mask = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:1017 in _create_rand_mask_from_inputs, code: rand_mask = torch.einsum("blq,bhlk->bhlqk", from_blocked_mask[:, 1:-1], rand_mask)
        getitem_3: "f32[1, 11, 64][832, 64, 1]cpu" = l_from_blocked_mask_[(slice(None, None, None), slice(1, -1, None))];  l_from_blocked_mask_ = None
        rand_mask_2: "f32[1, 12, 11, 64, 192][1622016, 135168, 12288, 192, 1]cpu" = torch.functional.einsum('blq,bhlk->bhlqk', getitem_3, rand_mask_1);  getitem_3 = rand_mask_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:602 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_query_matrix = query_layer.view(bsz, n_heads, from_seq_len // from_block_size, from_block_size, -1)
        blocked_query_matrix: "bf16[1, 12, 13, 64, 64][638976, 64, 49152, 768, 1]cpu" = l_query_layer_.view(1, 12, 13, 64, -1);  l_query_layer_ = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:603 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix = key_layer.view(bsz, n_heads, to_seq_len // to_block_size, to_block_size, -1)
        blocked_key_matrix: "bf16[1, 12, 13, 64, 64][638976, 64, 49152, 768, 1]cpu" = l_key_layer_.view(1, 12, 13, 64, -1)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:604 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix = value_layer.view(bsz, n_heads, to_seq_len // to_block_size, to_block_size, -1)
        blocked_value_matrix: "bf16[1, 12, 13, 64, 64][638976, 64, 49152, 768, 1]cpu" = l_value_layer_.view(1, 12, 13, 64, -1)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:972 in torch_gather_b2, code: shift = torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)
        shift: "i64[396][1]cpu" = torch.arange(396, device = device(type='cpu'))
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:973 in torch_gather_b2, code: indices_shift = torch.div(shift, num_indices_to_gather, rounding_mode="floor") * num_indices_to_pick_from
        div: "i64[396][1]cpu" = torch.div(shift, 33, rounding_mode = 'floor');  shift = None
        indices_shift: "i64[396][1]cpu" = div * 13;  div = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:975 in torch_gather_b2, code: flattened_indices = indices.view(-1) + indices_shift
        view_4: "i64[396][1]cpu" = rand_attn_2.view(-1)
        flattened_indices: "i64[396][1]cpu" = view_4 + indices_shift;  view_4 = indices_shift = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:976 in torch_gather_b2, code: flattened_params = params.reshape(-1, params.shape[-2], params.shape[-1])
        flattened_params: "bf16[156, 64, 64][4096, 64, 1]cpu" = blocked_key_matrix.reshape(-1, 64, 64)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:978 in torch_gather_b2, code: out_flattened = flattened_params.index_select(0, flattened_indices)
        out_flattened: "bf16[396, 64, 64][4096, 64, 1]cpu" = flattened_params.index_select(0, flattened_indices);  flattened_params = flattened_indices = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:980 in torch_gather_b2, code: out = out_flattened.reshape(params.shape[:2] + (num_indices_to_gather,) + params.shape[3:])
        out: "bf16[1, 12, 33, 64, 64][1622016, 135168, 4096, 64, 1]cpu" = out_flattened.reshape((1, 12, 33, 64, 64));  out_flattened = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:608 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_key = gathered_key.view(
        gathered_key: "bf16[1, 12, 11, 192, 64][1622016, 135168, 12288, 64, 1]cpu" = out.view(1, 12, 11, 192, -1);  out = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:972 in torch_gather_b2, code: shift = torch.arange(indices.shape[0] * indices.shape[1] * num_indices_to_gather, device=indices.device)
        shift_1: "i64[396][1]cpu" = torch.arange(396, device = device(type='cpu'))
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:973 in torch_gather_b2, code: indices_shift = torch.div(shift, num_indices_to_gather, rounding_mode="floor") * num_indices_to_pick_from
        div_1: "i64[396][1]cpu" = torch.div(shift_1, 33, rounding_mode = 'floor');  shift_1 = None
        indices_shift_1: "i64[396][1]cpu" = div_1 * 13;  div_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:975 in torch_gather_b2, code: flattened_indices = indices.view(-1) + indices_shift
        view_6: "i64[396][1]cpu" = rand_attn_2.view(-1)
        flattened_indices_1: "i64[396][1]cpu" = view_6 + indices_shift_1;  view_6 = indices_shift_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:976 in torch_gather_b2, code: flattened_params = params.reshape(-1, params.shape[-2], params.shape[-1])
        flattened_params_1: "bf16[156, 64, 64][4096, 64, 1]cpu" = blocked_value_matrix.reshape(-1, 64, 64)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:978 in torch_gather_b2, code: out_flattened = flattened_params.index_select(0, flattened_indices)
        out_flattened_1: "bf16[396, 64, 64][4096, 64, 1]cpu" = flattened_params_1.index_select(0, flattened_indices_1);  flattened_params_1 = flattened_indices_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:980 in torch_gather_b2, code: out = out_flattened.reshape(params.shape[:2] + (num_indices_to_gather,) + params.shape[3:])
        out_1: "bf16[1, 12, 33, 64, 64][1622016, 135168, 4096, 64, 1]cpu" = out_flattened_1.reshape((1, 12, 33, 64, 64));  out_flattened_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:612 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_value = gathered_value.view(
        gathered_value: "bf16[1, 12, 11, 192, 64][1622016, 135168, 12288, 64, 1]cpu" = out_1.view(1, 12, 11, 192, -1);  out_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:621 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, 0], key_layer, ndim=4)
        getitem_4: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_query_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_4: "bf16[12, 64, 64][64, 768, 1]cpu" = getitem_4.reshape((-1, 64, 64));  getitem_4 = None
        reshape_5: "bf16[12, 832, 64][64, 768, 1]cpu" = l_key_layer_.reshape((-1, 832, 64))
        transpose: "bf16[12, 64, 832][64, 1, 768]cpu" = reshape_5.transpose(1, 2);  reshape_5 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm: "bf16[12, 64, 832][53248, 832, 1]cpu" = torch.bmm(reshape_4, transpose);  reshape_4 = transpose = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        first_product: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = bmm.view((1, 12, 64, 832));  bmm = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:623 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_product = first_product * rsqrt_d
        first_product_1: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = first_product * 0.125;  first_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:624 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_product += (1.0 - to_mask) * attn_mask_penalty
        sub: "f32[1, 1, 1, 832][832, 832, 832, 1]cpu" = 1.0 - l_to_mask_
        mul_3: "f32[1, 1, 1, 832][832, 832, 832, 1]cpu" = sub * -10000.0;  sub = None
        first_product_1 += mul_3;  first_product_2: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = first_product_1;  first_product_1 = mul_3 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:625 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_attn_weights = nn.functional.softmax(
        first_attn_weights: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = torch.nn.functional.softmax(first_product_2, dim = -1);  first_product_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_6: "bf16[12, 64, 832][53248, 832, 1]cpu" = first_attn_weights.reshape((-1, 64, 832));  first_attn_weights = None
        reshape_7: "bf16[12, 832, 64][64, 768, 1]cpu" = l_value_layer_.reshape((-1, 832, 64))
        bmm_1: "bf16[12, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_6, reshape_7);  reshape_6 = reshape_7 = None
        first_context_layer: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = bmm_1.view((1, 12, 64, 64));  bmm_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:631 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_context_layer.unsqueeze_(2)
        unsqueeze__1: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = first_context_layer.unsqueeze_(2)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:641 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, 0],
        getitem_5: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:642 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, 1],
        getitem_6: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), 1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:643 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, 2],
        getitem_7: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), 2)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:644 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, -1],
        getitem_8: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), -1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:645 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_key[:, :, 0],
        getitem_9: "bf16[1, 12, 192, 64][1622016, 135168, 64, 1]cpu" = gathered_key[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:639 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_key_mat = torch.cat(
        second_key_mat: "bf16[1, 12, 448, 64][344064, 28672, 64, 1]cpu" = torch.cat([getitem_5, getitem_6, getitem_7, getitem_8, getitem_9], dim = 2);  getitem_5 = getitem_6 = getitem_7 = getitem_8 = getitem_9 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:651 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, 0],
        getitem_10: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:652 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, 1],
        getitem_11: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), 1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:653 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, 2],
        getitem_12: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), 2)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:654 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, -1],
        getitem_13: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), -1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:655 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_value[:, :, 0],
        getitem_14: "bf16[1, 12, 192, 64][1622016, 135168, 64, 1]cpu" = gathered_value[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:649 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_value_mat = torch.cat(
        second_value_mat: "bf16[1, 12, 448, 64][344064, 28672, 64, 1]cpu" = torch.cat([getitem_10, getitem_11, getitem_12, getitem_13, getitem_14], dim = 2);  getitem_10 = getitem_11 = getitem_12 = getitem_13 = getitem_14 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:661 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, 1], second_key_mat, ndim=4)
        getitem_15: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_query_matrix[(slice(None, None, None), slice(None, None, None), 1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_8: "bf16[12, 64, 64][64, 768, 1]cpu" = getitem_15.reshape((-1, 64, 64));  getitem_15 = None
        reshape_9: "bf16[12, 448, 64][28672, 64, 1]cpu" = second_key_mat.reshape((-1, 448, 64));  second_key_mat = None
        transpose_1: "bf16[12, 64, 448][28672, 1, 64]cpu" = reshape_9.transpose(1, 2);  reshape_9 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm_2: "bf16[12, 64, 448][28672, 448, 1]cpu" = torch.bmm(reshape_8, transpose_1);  reshape_8 = transpose_1 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        second_product: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = bmm_2.view((1, 12, 64, 448));  bmm_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:664 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask[:, :, :, : 3 * to_block_size],
        getitem_16: "f32[1, 1, 1, 192][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 192, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:665 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask[:, :, :, -to_block_size:],
        getitem_17: "f32[1, 1, 1, 64][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(-64, None, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:666 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask.new_ones([bsz, 1, 1, n_rand_blocks * to_block_size]),
        new_ones: "f32[1, 1, 1, 192][192, 192, 192, 1]cpu" = l_to_mask_.new_ones([1, 1, 1, 192])
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:662 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_seq_pad = torch.cat(
        second_seq_pad: "f32[1, 1, 1, 448][448, 448, 448, 1]cpu" = torch.cat([getitem_16, getitem_17, new_ones], dim = 3);  getitem_16 = getitem_17 = new_ones = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:672 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_mask.new_ones([bsz, n_heads, from_block_size, 4 * to_block_size]),
        new_ones_1: "f32[1, 12, 64, 256][196608, 16384, 256, 1]cpu" = rand_mask_2.new_ones([1, 12, 64, 256])
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:673 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_mask[:, :, 0],
        getitem_18: "f32[1, 12, 64, 192][1622016, 135168, 192, 1]cpu" = rand_mask_2[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:670 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_rand_pad = torch.cat(
        second_rand_pad: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.cat([new_ones_1, getitem_18], dim = 3);  new_ones_1 = getitem_18 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:677 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_product = second_product * rsqrt_d
        second_product_1: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = second_product * 0.125;  second_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:678 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_product += (1.0 - torch.minimum(second_seq_pad, second_rand_pad)) * attn_mask_penalty
        minimum: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.minimum(second_seq_pad, second_rand_pad);  second_seq_pad = second_rand_pad = None
        sub_1: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = 1.0 - minimum;  minimum = None
        mul_5: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = sub_1 * -10000.0;  sub_1 = None
        second_product_1 += mul_5;  second_product_2: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = second_product_1;  second_product_1 = mul_5 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:679 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_attn_weights = nn.functional.softmax(
        second_attn_weights: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.nn.functional.softmax(second_product_2, dim = -1);  second_product_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_10: "bf16[12, 64, 448][28672, 448, 1]cpu" = second_attn_weights.reshape((-1, 64, 448));  second_attn_weights = None
        reshape_11: "bf16[12, 448, 64][28672, 64, 1]cpu" = second_value_mat.reshape((-1, 448, 64));  second_value_mat = None
        bmm_3: "bf16[12, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_10, reshape_11);  reshape_10 = reshape_11 = None
        second_context_layer: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = bmm_3.view((1, 12, 64, 64));  bmm_3 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:686 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_context_layer.unsqueeze_(2)
        unsqueeze__2: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = second_context_layer.unsqueeze_(2)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:696 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: [blocked_key_matrix[:, :, 1:-3], blocked_key_matrix[:, :, 2:-2], blocked_key_matrix[:, :, 3:-1]], dim=3
        getitem_19: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), slice(1, -3, None))]
        getitem_20: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), slice(2, -2, None))]
        getitem_21: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), slice(3, -1, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:695 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: exp_blocked_key_matrix = torch.cat(
        exp_blocked_key_matrix: "bf16[1, 12, 9, 192, 64][1327104, 110592, 12288, 64, 1]cpu" = torch.cat([getitem_19, getitem_20, getitem_21], dim = 3);  getitem_19 = getitem_20 = getitem_21 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:699 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: [blocked_value_matrix[:, :, 1:-3], blocked_value_matrix[:, :, 2:-2], blocked_value_matrix[:, :, 3:-1]],
        getitem_22: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), slice(1, -3, None))]
        getitem_23: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), slice(2, -2, None))]
        getitem_24: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), slice(3, -1, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:698 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: exp_blocked_value_matrix = torch.cat(
        exp_blocked_value_matrix: "bf16[1, 12, 9, 192, 64][1327104, 110592, 12288, 64, 1]cpu" = torch.cat([getitem_22, getitem_23, getitem_24], dim = 3);  getitem_22 = getitem_23 = getitem_24 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:702 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: middle_query_matrix = blocked_query_matrix[:, :, 2:-2]
        middle_query_matrix: "bf16[1, 12, 9, 64, 64][638976, 64, 49152, 768, 1]cpu" = blocked_query_matrix[(slice(None, None, None), slice(None, None, None), slice(2, -2, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_12: "bf16[108, 64, 64][4096, 64, 1]cpu" = middle_query_matrix.reshape((-1, 64, 64))
        reshape_13: "bf16[108, 192, 64][12288, 64, 1]cpu" = exp_blocked_key_matrix.reshape((-1, 192, 64));  exp_blocked_key_matrix = None
        transpose_2: "bf16[108, 64, 192][12288, 1, 64]cpu" = reshape_13.transpose(1, 2);  reshape_13 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm_4: "bf16[108, 64, 192][12288, 192, 1]cpu" = torch.bmm(reshape_12, transpose_2);  reshape_12 = transpose_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        inner_band_product: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = bmm_4.view((1, 12, 9, 64, 192));  bmm_4 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:708 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: inner_band_product = inner_band_product * rsqrt_d
        inner_band_product_1: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = inner_band_product * 0.125;  inner_band_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:712 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_band_product = self.torch_bmm_nd_transpose(middle_query_matrix, gathered_key[:, :, 1:-1], ndim=5)
        getitem_26: "bf16[1, 12, 9, 192, 64][1622016, 135168, 12288, 64, 1]cpu" = gathered_key[(slice(None, None, None), slice(None, None, None), slice(1, -1, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_14: "bf16[108, 64, 64][4096, 64, 1]cpu" = middle_query_matrix.reshape((-1, 64, 64))
        reshape_15: "bf16[108, 192, 64][12288, 64, 1]cpu" = getitem_26.reshape((-1, 192, 64));  getitem_26 = None
        transpose_3: "bf16[108, 64, 192][12288, 1, 64]cpu" = reshape_15.transpose(1, 2);  reshape_15 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm_5: "bf16[108, 64, 192][12288, 192, 1]cpu" = torch.bmm(reshape_14, transpose_3);  reshape_14 = transpose_3 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        rand_band_product: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = bmm_5.view((1, 12, 9, 64, 192));  bmm_5 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:714 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_band_product = rand_band_product * rsqrt_d
        rand_band_product_1: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = rand_band_product * 0.125;  rand_band_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:718 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: "bhlqd,bhkd->bhlqk", middle_query_matrix, blocked_key_matrix[:, :, 0]
        getitem_27: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:717 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_band_product = torch.einsum(
        first_band_product: "bf16[1, 12, 9, 64, 64][64, 36864, 4096, 64, 1]cpu" = torch.functional.einsum('bhlqd,bhkd->bhlqk', middle_query_matrix, getitem_27);  getitem_27 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:720 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_band_product = first_band_product * rsqrt_d
        first_band_product_1: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = first_band_product * 0.125;  first_band_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:724 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: "bhlqd,bhkd->bhlqk", middle_query_matrix, blocked_key_matrix[:, :, -1]
        getitem_28: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), -1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:723 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_band_product = torch.einsum(
        last_band_product: "bf16[1, 12, 9, 64, 64][64, 36864, 4096, 64, 1]cpu" = torch.functional.einsum('bhlqd,bhkd->bhlqk', middle_query_matrix, getitem_28);  middle_query_matrix = getitem_28 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:726 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_band_product = last_band_product * rsqrt_d
        last_band_product_1: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = last_band_product * 0.125;  last_band_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:729 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: inner_band_product += (1.0 - band_mask) * attn_mask_penalty
        sub_2: "f32[1, 1, 9, 64, 192][110592, 110592, 12288, 192, 1]cpu" = 1.0 - l_band_mask_;  l_band_mask_ = None
        mul_10: "f32[1, 1, 9, 64, 192][110592, 110592, 12288, 192, 1]cpu" = sub_2 * -10000.0;  sub_2 = None
        inner_band_product_1 += mul_10;  inner_band_product_2: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = inner_band_product_1;  inner_band_product_1 = mul_10 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:730 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: first_band_product += (1.0 - to_mask[:, :, :, :to_block_size].unsqueeze(3)) * attn_mask_penalty
        getitem_29: "f32[1, 1, 1, 64][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 64, None))]
        unsqueeze: "f32[1, 1, 1, 1, 64][832, 832, 832, 64, 1]cpu" = getitem_29.unsqueeze(3);  getitem_29 = None
        sub_3: "f32[1, 1, 1, 1, 64][64, 64, 64, 64, 1]cpu" = 1.0 - unsqueeze;  unsqueeze = None
        mul_11: "f32[1, 1, 1, 1, 64][64, 64, 64, 64, 1]cpu" = sub_3 * -10000.0;  sub_3 = None
        first_band_product_1 += mul_11;  first_band_product_2: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = first_band_product_1;  first_band_product_1 = mul_11 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:731 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_band_product += (1.0 - to_mask[:, :, :, -to_block_size:].unsqueeze(3)) * attn_mask_penalty
        getitem_30: "f32[1, 1, 1, 64][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(-64, None, None))]
        unsqueeze_1: "f32[1, 1, 1, 1, 64][832, 832, 832, 64, 1]cpu" = getitem_30.unsqueeze(3);  getitem_30 = None
        sub_4: "f32[1, 1, 1, 1, 64][64, 64, 64, 64, 1]cpu" = 1.0 - unsqueeze_1;  unsqueeze_1 = None
        mul_12: "f32[1, 1, 1, 1, 64][64, 64, 64, 64, 1]cpu" = sub_4 * -10000.0;  sub_4 = None
        last_band_product_1 += mul_12;  last_band_product_2: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = last_band_product_1;  last_band_product_1 = mul_12 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:732 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_band_product += (1.0 - rand_mask[:, :, 1:-1]) * attn_mask_penalty
        getitem_31: "f32[1, 12, 9, 64, 192][1622016, 135168, 12288, 192, 1]cpu" = rand_mask_2[(slice(None, None, None), slice(None, None, None), slice(1, -1, None))]
        sub_5: "f32[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = 1.0 - getitem_31;  getitem_31 = None
        mul_13: "f32[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = sub_5 * -10000.0;  sub_5 = None
        rand_band_product_1 += mul_13;  rand_band_product_2: "bf16[1, 12, 9, 64, 192][1327104, 110592, 12288, 192, 1]cpu" = rand_band_product_1;  rand_band_product_1 = mul_13 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:735 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: band_product = torch.cat(
        band_product: "bf16[1, 12, 9, 64, 512][3538944, 294912, 32768, 512, 1]cpu" = torch.cat([first_band_product_2, inner_band_product_2, rand_band_product_2, last_band_product_2], dim = -1);  first_band_product_2 = inner_band_product_2 = rand_band_product_2 = last_band_product_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:740 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: attn_weights = nn.functional.softmax(
        attn_weights: "bf16[1, 12, 9, 64, 512][3538944, 294912, 32768, 512, 1]cpu" = torch.nn.functional.softmax(band_product, dim = -1);  band_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:747 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: attn_weights[:, :, :, :, to_block_size : 4 * to_block_size], exp_blocked_value_matrix, ndim=5
        getitem_32: "bf16[1, 12, 9, 64, 192][3538944, 294912, 32768, 512, 1]cpu" = attn_weights[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(64, 256, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_16: "bf16[108, 64, 192][32768, 512, 1]cpu" = getitem_32.reshape((-1, 64, 192));  getitem_32 = None
        reshape_17: "bf16[108, 192, 64][12288, 64, 1]cpu" = exp_blocked_value_matrix.reshape((-1, 192, 64));  exp_blocked_value_matrix = None
        bmm_6: "bf16[108, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_16, reshape_17);  reshape_16 = reshape_17 = None
        context_layer: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = bmm_6.view((1, 12, 9, 64, 64));  bmm_6 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:754 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: attn_weights[:, :, :, :, 4 * to_block_size : -to_block_size], gathered_value[:, :, 1:-1], ndim=5
        getitem_33: "bf16[1, 12, 9, 64, 192][3538944, 294912, 32768, 512, 1]cpu" = attn_weights[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(256, -64, None))]
        getitem_34: "bf16[1, 12, 9, 192, 64][1622016, 135168, 12288, 64, 1]cpu" = gathered_value[(slice(None, None, None), slice(None, None, None), slice(1, -1, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_18: "bf16[108, 64, 192][32768, 512, 1]cpu" = getitem_33.reshape((-1, 64, 192));  getitem_33 = None
        reshape_19: "bf16[108, 192, 64][12288, 64, 1]cpu" = getitem_34.reshape((-1, 192, 64));  getitem_34 = None
        bmm_7: "bf16[108, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_18, reshape_19);  reshape_18 = reshape_19 = None
        view_15: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = bmm_7.view((1, 12, 9, 64, 64));  bmm_7 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:753 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer += self.torch_bmm_nd(
        context_layer += view_15;  context_layer_1: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = context_layer;  context_layer = view_15 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:760 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: "bhlqk,bhkd->bhlqd", attn_weights[:, :, :, :, :to_block_size], blocked_value_matrix[:, :, 0]
        getitem_35: "bf16[1, 12, 9, 64, 64][3538944, 294912, 32768, 512, 1]cpu" = attn_weights[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 64, None))]
        getitem_36: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:759 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer += torch.einsum(
        einsum_3: "bf16[1, 12, 9, 64, 64][64, 36864, 4096, 64, 1]cpu" = torch.functional.einsum('bhlqk,bhkd->bhlqd', getitem_35, getitem_36);  getitem_35 = getitem_36 = None
        context_layer_1 += einsum_3;  context_layer_2: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = context_layer_1;  context_layer_1 = einsum_3 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:763 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: "bhlqk,bhkd->bhlqd", attn_weights[:, :, :, :, -to_block_size:], blocked_value_matrix[:, :, -1]
        getitem_37: "bf16[1, 12, 9, 64, 64][3538944, 294912, 32768, 512, 1]cpu" = attn_weights[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(-64, None, None))];  attn_weights = None
        getitem_38: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), -1)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:762 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer += torch.einsum(
        einsum_4: "bf16[1, 12, 9, 64, 64][64, 36864, 4096, 64, 1]cpu" = torch.functional.einsum('bhlqk,bhkd->bhlqd', getitem_37, getitem_38);  getitem_37 = getitem_38 = None
        context_layer_2 += einsum_4;  context_layer_3: "bf16[1, 12, 9, 64, 64][442368, 36864, 4096, 64, 1]cpu" = context_layer_2;  context_layer_2 = einsum_4 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:775 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, 0],
        getitem_39: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:776 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, -3],
        getitem_40: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), -3)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:777 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, -2],
        getitem_41: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), -2)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:778 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_key_matrix[:, :, -1],
        getitem_42: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_key_matrix[(slice(None, None, None), slice(None, None, None), -1)];  blocked_key_matrix = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:779 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_key[:, :, -1],
        getitem_43: "bf16[1, 12, 192, 64][1622016, 135168, 64, 1]cpu" = gathered_key[(slice(None, None, None), slice(None, None, None), -1)];  gathered_key = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:773 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_key_mat = torch.cat(
        second_last_key_mat: "bf16[1, 12, 448, 64][344064, 28672, 64, 1]cpu" = torch.cat([getitem_39, getitem_40, getitem_41, getitem_42, getitem_43], dim = 2);  getitem_39 = getitem_40 = getitem_41 = getitem_42 = getitem_43 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:785 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, 0],
        getitem_44: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), 0)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:786 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, -3],
        getitem_45: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), -3)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:787 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, -2],
        getitem_46: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), -2)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:788 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: blocked_value_matrix[:, :, -1],
        getitem_47: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_value_matrix[(slice(None, None, None), slice(None, None, None), -1)];  blocked_value_matrix = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:789 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: gathered_value[:, :, -1],
        getitem_48: "bf16[1, 12, 192, 64][1622016, 135168, 64, 1]cpu" = gathered_value[(slice(None, None, None), slice(None, None, None), -1)];  gathered_value = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:783 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_value_mat = torch.cat(
        second_last_value_mat: "bf16[1, 12, 448, 64][344064, 28672, 64, 1]cpu" = torch.cat([getitem_44, getitem_45, getitem_46, getitem_47, getitem_48], dim = 2);  getitem_44 = getitem_45 = getitem_46 = getitem_47 = getitem_48 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:795 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, -2], second_last_key_mat, ndim=4)
        getitem_49: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_query_matrix[(slice(None, None, None), slice(None, None, None), -2)]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_20: "bf16[12, 64, 64][64, 768, 1]cpu" = getitem_49.reshape((-1, 64, 64));  getitem_49 = None
        reshape_21: "bf16[12, 448, 64][28672, 64, 1]cpu" = second_last_key_mat.reshape((-1, 448, 64));  second_last_key_mat = None
        transpose_4: "bf16[12, 64, 448][28672, 1, 64]cpu" = reshape_21.transpose(1, 2);  reshape_21 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm_8: "bf16[12, 64, 448][28672, 448, 1]cpu" = torch.bmm(reshape_20, transpose_4);  reshape_20 = transpose_4 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        second_last_product: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = bmm_8.view((1, 12, 64, 448));  bmm_8 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:798 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask[:, :, :, :to_block_size],
        getitem_50: "f32[1, 1, 1, 64][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(None, 64, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:799 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask[:, :, :, -3 * to_block_size :],
        getitem_51: "f32[1, 1, 1, 192][832, 832, 832, 1]cpu" = l_to_mask_[(slice(None, None, None), slice(None, None, None), slice(None, None, None), slice(-192, None, None))]
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:800 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: to_mask.new_ones([bsz, 1, 1, n_rand_blocks * to_block_size]),
        new_ones_2: "f32[1, 1, 1, 192][192, 192, 192, 1]cpu" = l_to_mask_.new_ones([1, 1, 1, 192])
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:796 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_seq_pad = torch.cat(
        second_last_seq_pad: "f32[1, 1, 1, 448][448, 448, 448, 1]cpu" = torch.cat([getitem_50, getitem_51, new_ones_2], dim = 3);  getitem_50 = getitem_51 = new_ones_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:806 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_mask.new_ones([bsz, n_heads, from_block_size, 4 * to_block_size]),
        new_ones_3: "f32[1, 12, 64, 256][196608, 16384, 256, 1]cpu" = rand_mask_2.new_ones([1, 12, 64, 256])
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:807 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: rand_mask[:, :, -1],
        getitem_52: "f32[1, 12, 64, 192][1622016, 135168, 192, 1]cpu" = rand_mask_2[(slice(None, None, None), slice(None, None, None), -1)];  rand_mask_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:804 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_rand_pad = torch.cat(
        second_last_rand_pad: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.cat([new_ones_3, getitem_52], dim = 3);  new_ones_3 = getitem_52 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:811 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_product = second_last_product * rsqrt_d
        second_last_product_1: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = second_last_product * 0.125;  second_last_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:812 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_product += (1.0 - torch.minimum(second_last_seq_pad, second_last_rand_pad)) * attn_mask_penalty
        minimum_1: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.minimum(second_last_seq_pad, second_last_rand_pad);  second_last_seq_pad = second_last_rand_pad = None
        sub_6: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = 1.0 - minimum_1;  minimum_1 = None
        mul_15: "f32[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = sub_6 * -10000.0;  sub_6 = None
        second_last_product_1 += mul_15;  second_last_product_2: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = second_last_product_1;  second_last_product_1 = mul_15 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:813 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_attn_weights = nn.functional.softmax(
        second_last_attn_weights: "bf16[1, 12, 64, 448][344064, 28672, 448, 1]cpu" = torch.nn.functional.softmax(second_last_product_2, dim = -1);  second_last_product_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_22: "bf16[12, 64, 448][28672, 448, 1]cpu" = second_last_attn_weights.reshape((-1, 64, 448));  second_last_attn_weights = None
        reshape_23: "bf16[12, 448, 64][28672, 64, 1]cpu" = second_last_value_mat.reshape((-1, 448, 64));  second_last_value_mat = None
        bmm_9: "bf16[12, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_22, reshape_23);  reshape_22 = reshape_23 = None
        second_last_context_layer: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = bmm_9.view((1, 12, 64, 64));  bmm_9 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:819 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: second_last_context_layer.unsqueeze_(2)
        unsqueeze__3: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = second_last_context_layer.unsqueeze_(2)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:826 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_product = self.torch_bmm_nd_transpose(blocked_query_matrix[:, :, -1], key_layer, ndim=4)
        getitem_53: "bf16[1, 12, 64, 64][638976, 64, 768, 1]cpu" = blocked_query_matrix[(slice(None, None, None), slice(None, None, None), -1)];  blocked_query_matrix = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:513 in torch_bmm_nd_transpose, code: inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2)
        reshape_24: "bf16[12, 64, 64][64, 768, 1]cpu" = getitem_53.reshape((-1, 64, 64));  getitem_53 = None
        reshape_25: "bf16[12, 832, 64][64, 768, 1]cpu" = l_key_layer_.reshape((-1, 832, 64));  l_key_layer_ = None
        transpose_5: "bf16[12, 64, 832][64, 1, 768]cpu" = reshape_25.transpose(1, 2);  reshape_25 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:512 in torch_bmm_nd_transpose, code: return torch.bmm(
        bmm_10: "bf16[12, 64, 832][53248, 832, 1]cpu" = torch.bmm(reshape_24, transpose_5);  reshape_24 = transpose_5 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:514 in torch_bmm_nd_transpose, code: ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))
        last_product: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = bmm_10.view((1, 12, 64, 832));  bmm_10 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:827 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_product = last_product * rsqrt_d
        last_product_1: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = last_product * 0.125;  last_product = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:828 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_product += (1.0 - to_mask) * attn_mask_penalty
        sub_7: "f32[1, 1, 1, 832][832, 832, 832, 1]cpu" = 1.0 - l_to_mask_;  l_to_mask_ = None
        mul_17: "f32[1, 1, 1, 832][832, 832, 832, 1]cpu" = sub_7 * -10000.0;  sub_7 = None
        last_product_1 += mul_17;  last_product_2: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = last_product_1;  last_product_1 = mul_17 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:829 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_attn_weights = nn.functional.softmax(last_product, dim=-1)  # [bsz, n_heads, from_block_size, n]
        last_attn_weights: "bf16[1, 12, 64, 832][638976, 53248, 832, 1]cpu" = torch.nn.functional.softmax(last_product_2, dim = -1);  last_product_2 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:504 in torch_bmm_nd, code: return torch.bmm(inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])).view(
        reshape_26: "bf16[12, 64, 832][53248, 832, 1]cpu" = last_attn_weights.reshape((-1, 64, 832));  last_attn_weights = None
        reshape_27: "bf16[12, 832, 64][64, 768, 1]cpu" = l_value_layer_.reshape((-1, 832, 64));  l_value_layer_ = None
        bmm_11: "bf16[12, 64, 64][4096, 64, 1]cpu" = torch.bmm(reshape_26, reshape_27);  reshape_26 = reshape_27 = None
        last_context_layer: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = bmm_11.view((1, 12, 64, 64));  bmm_11 = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:833 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: last_context_layer.unsqueeze_(2)
        unsqueeze__4: "bf16[1, 12, 1, 64, 64][49152, 4096, 4096, 64, 1]cpu" = last_context_layer.unsqueeze_(2)
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:836 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer = torch.cat(
        context_layer_4: "bf16[1, 12, 13, 64, 64][638976, 53248, 4096, 64, 1]cpu" = torch.cat([first_context_layer, second_context_layer, context_layer_3, second_last_context_layer, last_context_layer], dim = 2);  first_context_layer = second_context_layer = context_layer_3 = second_last_context_layer = last_context_layer = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:840 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer = context_layer.view((bsz, n_heads, from_seq_len, -1)) * from_mask
        view_20: "bf16[1, 12, 832, 64][638976, 53248, 64, 1]cpu" = context_layer_4.view((1, 12, 832, -1));  context_layer_4 = None
        context_layer_5: "f32[1, 12, 832, 64][638976, 53248, 64, 1]cpu" = view_20 * l_from_mask_;  view_20 = l_from_mask_ = None
        
        # File: /localdisk/leslie/miniconda/envs/pytorch_community/lib/python3.10/site-packages/transformers/models/big_bird/modeling_big_bird.py:841 in torch_dynamo_resume_in_bigbird_block_sparse_attention_at_583, code: context_layer = torch.transpose(context_layer, 1, 2)
        context_layer_6: "f32[1, 832, 12, 64][638976, 64, 53248, 1]cpu" = torch.transpose(context_layer_5, 1, 2);  context_layer_5 = None
        return (context_layer_6, rand_attn_2)
        